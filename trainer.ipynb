{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"DNdeym-6lgtW","executionInfo":{"status":"ok","timestamp":1707411911628,"user_tz":-210,"elapsed":8610,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"px47jXhOljRs","executionInfo":{"status":"ok","timestamp":1707411953098,"user_tz":-210,"elapsed":38368,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}},"outputId":"8102f9e2-6af4-48c1-cab7-4cf8320cdf95"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GM7mm-YYlgtc"},"outputs":[],"source":["# from pickle import NONE\n","# IMAGE_NUM = 7129\n","# path =  \"/content/drive/MyDrive/image_to_str/sample_data/\"\n","# train_list = []\n","# for i in range(1001):\n","#       img = cv2.imread(path + str(i)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n","#       train_list.append(img)\n","\n","# test_list = []\n","\n","# for i in range(5600,IMAGE_NUM):\n","#     img = cv2.imread(path + str(i)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n","#     test_list.append(img)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fiiwWssPlgtd","executionInfo":{"status":"ok","timestamp":1707412016196,"user_tz":-210,"elapsed":2,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["x_transform = A.Compose(\n","    [\n","     A.Resize(150,150),\n","     A.HorizontalFlip(p=0.5),\n","     A.VerticalFlip(p=0.5),\n","     ToTensorV2(),\n","     ]\n",")\n","\n","test_transform = A.Compose(\n","    [\n","    A.Resize(150,150),\n","    ToTensorV2(),\n","     ]\n",")\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"157AunBAlgtd","executionInfo":{"status":"ok","timestamp":1707412019734,"user_tz":-210,"elapsed":449,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, image_paths, transform=False):\n","        self.image_paths = image_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image = np.array(self.image_paths[idx])\n","        # image = cv2.imread(image_filepath)\n","\n","\n","        # print(label)\n","        if self.transform != False:\n","            image = self.transform(image=image)[\"image\"]\n","\n","        return image.float()\n","\n","\n","\n","train_dataset = ImageDataset(train_list,x_transform)\n","\n","# test_dataset = ImageDataset(test_list)"]},{"cell_type":"code","source":["# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","# for batch in train_dataloader:\n","#   print(batch)"],"metadata":{"id":"-lbuk-Bhvf2r","executionInfo":{"status":"ok","timestamp":1707401254615,"user_tz":-210,"elapsed":1,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["import torch\n","# torch.save(train_dataset, \"/content/drive/MyDrive/image_to_str/train_ds.pt\")\n","train_dataset = torch.load(\"/content/drive/MyDrive/image_to_str/train_ds.pt\")"],"metadata":{"id":"1kqZcjolm7ay","executionInfo":{"status":"ok","timestamp":1707412023144,"user_tz":-210,"elapsed":9,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hssaMnkXp3fr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xP5IDcAqlgte","executionInfo":{"status":"ok","timestamp":1707412027937,"user_tz":-210,"elapsed":7,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["import torch.nn as nn\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(1, 256, (5,5), 1, (1, 1), bias=True),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 512, (5, 5), 1, (0, 0), bias=True),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(True),\n","            nn.Conv2d(512, 256, (5, 5), 1, (0,0), bias=True),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 64, (5,5), 2, (0, 0), bias=True),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","            nn.Conv2d(64, 5, (5, 5), 1, (0, 0), bias=True),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQ3pWRKvlgtf","executionInfo":{"status":"ok","timestamp":1707412034831,"user_tz":-210,"elapsed":1428,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}},"outputId":"99719707-ea7a-4f78-e4a5-1c713dfdb740"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1        [-1, 256, 148, 148]           6,656\n","       BatchNorm2d-2        [-1, 256, 148, 148]             512\n","              ReLU-3        [-1, 256, 148, 148]               0\n","            Conv2d-4        [-1, 512, 144, 144]       3,277,312\n","       BatchNorm2d-5        [-1, 512, 144, 144]           1,024\n","              ReLU-6        [-1, 512, 144, 144]               0\n","            Conv2d-7        [-1, 256, 140, 140]       3,277,056\n","       BatchNorm2d-8        [-1, 256, 140, 140]             512\n","              ReLU-9        [-1, 256, 140, 140]               0\n","           Conv2d-10           [-1, 64, 68, 68]         409,664\n","      BatchNorm2d-11           [-1, 64, 68, 68]             128\n","             ReLU-12           [-1, 64, 68, 68]               0\n","           Conv2d-13            [-1, 5, 64, 64]           8,005\n","          Sigmoid-14            [-1, 5, 64, 64]               0\n","================================================================\n","Total params: 6,980,869\n","Trainable params: 6,980,869\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.09\n","Forward/backward pass size (MB): 493.27\n","Params size (MB): 26.63\n","Estimated Total Size (MB): 519.99\n","----------------------------------------------------------------\n","None\n"]}],"source":["from torchsummary import summary\n","print(summary(Generator().to(\"cuda\"), (1,150, 150)))"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"i4blFTNOlgtg","executionInfo":{"status":"ok","timestamp":1707412726733,"user_tz":-210,"elapsed":890,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["import torch\n","class Discriminator(nn.Module):\n","    def __init__(self) -> None:\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(1, 16, (4, 4), (2, 2), (1, 1)),\n","            nn.LeakyReLU(0.2, True),\n","            # State size. 64 x 64 x 64\n","            nn.Conv2d(16, 32, (4, 4), (2, 2), (1, 1)),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.2, True),\n","            # State size. 128 x 32 x 32\n","            nn.Conv2d(32, 64, (4, 4), (2, 2), (1, 1)),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2, True),\n","            # State size. 256 x 16 x 16\n","            nn.Conv2d(64, 128, (4, 4), (2, 2), (1, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, True),\n","            # State size. 512 x 8 x 8\n","            nn.Conv2d(128, 256, (4, 4), (2, 2), (1, 1)),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Conv2d(256, 1, (4, 4), (1, 1), (0, 0)),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        out = self.main(x)\n","        out = torch.flatten(out, 1)\n","\n","        return out"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYIKB1tJlgth","executionInfo":{"status":"ok","timestamp":1707412042403,"user_tz":-210,"elapsed":7,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}},"outputId":"827064f5-910e-4187-8bc9-ffc9bec0ab8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 75, 75]             272\n","         LeakyReLU-2           [-1, 16, 75, 75]               0\n","            Conv2d-3           [-1, 32, 37, 37]           8,192\n","       BatchNorm2d-4           [-1, 32, 37, 37]              64\n","         LeakyReLU-5           [-1, 32, 37, 37]               0\n","            Conv2d-6           [-1, 64, 18, 18]          32,768\n","       BatchNorm2d-7           [-1, 64, 18, 18]             128\n","         LeakyReLU-8           [-1, 64, 18, 18]               0\n","            Conv2d-9            [-1, 128, 9, 9]         131,072\n","      BatchNorm2d-10            [-1, 128, 9, 9]             256\n","        LeakyReLU-11            [-1, 128, 9, 9]               0\n","           Conv2d-12            [-1, 256, 4, 4]         524,544\n","      BatchNorm2d-13            [-1, 256, 4, 4]             512\n","        LeakyReLU-14            [-1, 256, 4, 4]               0\n","           Conv2d-15              [-1, 1, 1, 1]           4,097\n","          Sigmoid-16              [-1, 1, 1, 1]               0\n","================================================================\n","Total params: 701,905\n","Trainable params: 701,905\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.09\n","Forward/backward pass size (MB): 3.18\n","Params size (MB): 2.68\n","Estimated Total Size (MB): 5.95\n","----------------------------------------------------------------\n","None\n"]}],"source":["from torchsummary import summary\n","print(summary(Discriminator().to(\"cuda\"), (1,150, 150)))"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"0RNG5FGIlgth","executionInfo":{"status":"ok","timestamp":1707412919089,"user_tz":-210,"elapsed":401,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["def create_tensor_from_tensor(tensor):\n","    values = [np.array([[0,0,0],[0,0,0],[0,0,0]]),np.array([[255,0,255],[255,0,255],[255,0,255]]),np.array([[0,255,255],[255,0,255],[0,255,255]]),np.array([[255,255,0],[255,0,255],[255,255,0]]),np.array([[255,255,0],[255,0,255],[255,255,0]]),np.array([[255,255,255],[255,255,255],[255,255,255]])]\n","    indexes = torch.argmax(tensor,dim=1)\n","    output_tensor = np.zeros((tensor.shape[0],3*tensor.shape[2],3*tensor.shape[3]))\n","    for k in range(tensor.shape[0]):\n","        for i in range(0,tensor.shape[2],1):\n","            for j in range(0,tensor.shape[3],1):\n","                index = indexes[k, i, j]\n","                output_tensor[k,i*3:(i*3)+3, j*3:(j*3)+3] = values[index]\n","    result = np.zeros((tensor.shape[0],150,150))\n","    for k in range(tensor.shape[0]):\n","        result[k,:,:] = cv2.resize(output_tensor[k,:,:], (150,150))\n","    final_result = np.zeros((tensor.shape[0],1,150,150))\n","    final_result[:,0,:,:] = result\n","    return torch.from_numpy(final_result).float()\n","\n","def process(input_tensor):\n","    chars  = ['@', '|', '>', '<', ' ']\n","    tensor = create_tensor_from_tensor(input_tensor)\n","    return tensor\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"EgTOXkDMlgti","executionInfo":{"status":"ok","timestamp":1707412377100,"user_tz":-210,"elapsed":2,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","discriminator = Discriminator().to(\"cuda\")\n","generator  = Generator().to(\"cuda\")\n","\n","criterion = nn.BCELoss().to(\"cuda\")\n","d_optimizer = torch.optim.Adam(discriminator.parameters(), 0.0002, (0.5, 0.999))\n","g_optimizer = torch.optim.Adam(generator.parameters(),     0.0002, (0.5, 0.999))"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"XthhKzWXlgti","executionInfo":{"status":"ok","timestamp":1707412940459,"user_tz":-210,"elapsed":4,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"outputs":[],"source":["\n","from torch.utils.tensorboard import SummaryWriter\n","import os\n","\n","writer = SummaryWriter(os.path.join(\"samples\",  \"logs\", \"model_log\"))\n","def train(dataloader, epoch):\n","    batches = len(dataloader)\n","\n","    discriminator.train()\n","    generator.train()\n","\n","    for index, real in enumerate(train_dataloader):\n","        # print(real)\n","        real = real.to(\"cuda\")\n","        label_size = real.size(0)\n","        real_label = torch.full([label_size, 1], 1.0, dtype=real.dtype, device=\"cuda\")\n","        fake_label = torch.full([label_size, 1], 0.0, dtype=real.dtype, device=\"cuda\")\n","        discriminator.zero_grad()\n","        # print(real.shape)\n","        output = discriminator(real)\n","        d_loss_real = criterion(output, real_label)\n","        d_loss_real.backward()\n","        d_real = output.mean().item()\n","        # Generate a fake image.\n","        fake = generator(real)\n","        # print(fake.shape)\n","        fake = process(fake.to(\"cpu\")).to(\"cuda\")\n","        # print(fake.shape)\n","        output = discriminator(fake.to(\"cuda\"))\n","        d_loss_fake = criterion(output, fake_label)\n","        d_loss_fake.backward()\n","        d_fake1 = output.mean().item()\n","        d_loss = d_loss_real + d_loss_fake\n","        d_optimizer.step()\n","\n","        generator.zero_grad()\n","        output = discriminator(fake)\n","        g_loss = criterion(output, real_label)\n","        g_loss.backward()\n","        g_optimizer.step()\n","        d_fake2 = output.mean().item()\n","\n","        iters = index + epoch * batches + 1\n","        writer.add_scalar(\"Train_Adversarial/D_Loss\", d_loss.item(), iters)\n","        writer.add_scalar(\"Train_Adversarial/G_Loss\", g_loss.item(), iters)\n","        writer.add_scalar(\"Train_Adversarial/D_Real\", d_real, iters)\n","        writer.add_scalar(\"Train_Adversarial/D_Fake1\", d_fake1, iters)\n","        writer.add_scalar(\"Train_Adversarial/D_Fake2\", d_fake2, iters)\n","        # Print the loss function every ten iterations and the last iteration in this epoch.\n","        if (index + 1) % 10 == 0 or (index + 1) == batches:\n","            print(f\"Train stage: adversarial \"\n","                  f\"Epoch[{epoch}] \"\n","                  f\"D Loss: {d_loss.item():.6f} G Loss: {g_loss.item():.6f} \"\n","                  f\"D(Real): {d_real:.6f} D(Fake1)/D(Fake2): {d_fake1:.6f}/{d_fake2:.6f}.\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"kJvFfcyGu2Ol"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w86vzDSYlgtj","executionInfo":{"status":"ok","timestamp":1707413924432,"user_tz":-210,"elapsed":981600,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}},"outputId":"7c2f25ce-f9c3-4c09-9489-cdbcacaa6099"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train stage: adversarial Epoch[0] D Loss: 0.061423 G Loss: 4.044600 D(Real): 0.963671 D(Fake1)/D(Fake2): 0.024123/0.017517.\n","Train stage: adversarial Epoch[0] D Loss: 0.055247 G Loss: 3.651229 D(Real): 0.996443 D(Fake1)/D(Fake2): 0.050371/0.025959.\n","Train stage: adversarial Epoch[0] D Loss: 0.076641 G Loss: 4.167836 D(Real): 0.946431 D(Fake1)/D(Fake2): 0.021352/0.015486.\n","Train stage: adversarial Epoch[0] D Loss: 0.052976 G Loss: 5.704596 D(Real): 0.951695 D(Fake1)/D(Fake2): 0.003459/0.003331.\n","Train stage: adversarial Epoch[0] D Loss: 0.006374 G Loss: 5.836685 D(Real): 0.996690 D(Fake1)/D(Fake2): 0.003054/0.002919.\n","Train stage: adversarial Epoch[0] D Loss: 0.014881 G Loss: 5.467773 D(Real): 0.989702 D(Fake1)/D(Fake2): 0.004520/0.004221.\n","Train stage: adversarial Epoch[0] D Loss: 0.021334 G Loss: 4.460297 D(Real): 0.995016 D(Fake1)/D(Fake2): 0.016205/0.011559.\n","Train stage: adversarial Epoch[0] D Loss: 0.049204 G Loss: 6.438440 D(Real): 0.953427 D(Fake1)/D(Fake2): 0.001510/0.001599.\n","Train stage: adversarial Epoch[0] D Loss: 0.009024 G Loss: 5.194829 D(Real): 0.997651 D(Fake1)/D(Fake2): 0.006650/0.005545.\n","Train stage: adversarial Epoch[0] D Loss: 0.012800 G Loss: 5.019297 D(Real): 0.995059 D(Fake1)/D(Fake2): 0.007817/0.006609.\n","Train stage: adversarial Epoch[0] D Loss: 0.007930 G Loss: 6.700495 D(Real): 0.993334 D(Fake1)/D(Fake2): 0.001241/0.001230.\n","Train stage: adversarial Epoch[0] D Loss: 0.003509 G Loss: 7.085254 D(Real): 0.997350 D(Fake1)/D(Fake2): 0.000856/0.000837.\n","Train stage: adversarial Epoch[0] D Loss: 0.004513 G Loss: 5.829650 D(Real): 0.998653 D(Fake1)/D(Fake2): 0.003161/0.002939.\n","Train stage: adversarial Epoch[0] D Loss: 0.010687 G Loss: 7.107819 D(Real): 0.990203 D(Fake1)/D(Fake2): 0.000841/0.000819.\n","Train stage: adversarial Epoch[0] D Loss: 0.004790 G Loss: 6.549722 D(Real): 0.996720 D(Fake1)/D(Fake2): 0.001503/0.001431.\n","Train stage: adversarial Epoch[0] D Loss: 0.004845 G Loss: 6.517517 D(Real): 0.996734 D(Fake1)/D(Fake2): 0.001572/0.001477.\n","Train stage: adversarial Epoch[0] D Loss: 0.010438 G Loss: 4.951783 D(Real): 0.999292 D(Fake1)/D(Fake2): 0.009682/0.007071.\n","Train stage: adversarial Epoch[0] D Loss: 0.001367 G Loss: 7.694245 D(Real): 0.999092 D(Fake1)/D(Fake2): 0.000459/0.000455.\n","Train stage: adversarial Epoch[0] D Loss: 0.009955 G Loss: 7.029556 D(Real): 0.990974 D(Fake1)/D(Fake2): 0.000887/0.000885.\n","Train stage: adversarial Epoch[0] D Loss: 0.001356 G Loss: 7.220266 D(Real): 0.999398 D(Fake1)/D(Fake2): 0.000753/0.000732.\n","Train stage: adversarial Epoch[0] D Loss: 0.001528 G Loss: 8.135778 D(Real): 0.998766 D(Fake1)/D(Fake2): 0.000294/0.000293.\n","Train stage: adversarial Epoch[0] D Loss: 0.001898 G Loss: 7.210888 D(Real): 0.998863 D(Fake1)/D(Fake2): 0.000760/0.000739.\n","Train stage: adversarial Epoch[0] D Loss: 0.001191 G Loss: 7.667481 D(Real): 0.999283 D(Fake1)/D(Fake2): 0.000474/0.000468.\n","Train stage: adversarial Epoch[0] D Loss: 0.003501 G Loss: 7.641823 D(Real): 0.996991 D(Fake1)/D(Fake2): 0.000488/0.000480.\n","Train stage: adversarial Epoch[0] D Loss: 0.011128 G Loss: 4.882520 D(Real): 0.999858 D(Fake1)/D(Fake2): 0.010926/0.007578.\n","Train stage: adversarial Epoch[0] D Loss: 0.001775 G Loss: 7.296712 D(Real): 0.998921 D(Fake1)/D(Fake2): 0.000696/0.000678.\n","Train stage: adversarial Epoch[0] D Loss: 0.007124 G Loss: 5.281701 D(Real): 0.999241 D(Fake1)/D(Fake2): 0.006344/0.005084.\n","Train stage: adversarial Epoch[0] D Loss: 0.002873 G Loss: 8.559682 D(Real): 0.997321 D(Fake1)/D(Fake2): 0.000190/0.000192.\n","Train stage: adversarial Epoch[0] D Loss: 0.002934 G Loss: 8.613408 D(Real): 0.997251 D(Fake1)/D(Fake2): 0.000181/0.000182.\n","Train stage: adversarial Epoch[0] D Loss: 0.001371 G Loss: 8.629542 D(Real): 0.998811 D(Fake1)/D(Fake2): 0.000181/0.000179.\n","Train stage: adversarial Epoch[0] D Loss: 0.001024 G Loss: 8.926804 D(Real): 0.999110 D(Fake1)/D(Fake2): 0.000133/0.000133.\n","Train stage: adversarial Epoch[0] D Loss: 0.000645 G Loss: 8.299147 D(Real): 0.999605 D(Fake1)/D(Fake2): 0.000251/0.000249.\n","Train stage: adversarial Epoch[0] D Loss: 0.000599 G Loss: 9.247814 D(Real): 0.999498 D(Fake1)/D(Fake2): 0.000097/0.000096.\n","Train stage: adversarial Epoch[0] D Loss: 0.001365 G Loss: 8.004560 D(Real): 0.998965 D(Fake1)/D(Fake2): 0.000330/0.000334.\n","Train stage: adversarial Epoch[0] D Loss: 0.001490 G Loss: 7.269833 D(Real): 0.999222 D(Fake1)/D(Fake2): 0.000711/0.000696.\n","Train stage: adversarial Epoch[0] D Loss: 0.000453 G Loss: 8.660919 D(Real): 0.999722 D(Fake1)/D(Fake2): 0.000175/0.000173.\n","Train stage: adversarial Epoch[0] D Loss: 0.001018 G Loss: 8.871209 D(Real): 0.999123 D(Fake1)/D(Fake2): 0.000141/0.000140.\n","Train stage: adversarial Epoch[0] D Loss: 0.001838 G Loss: 6.424322 D(Real): 0.999891 D(Fake1)/D(Fake2): 0.001727/0.001622.\n","Train stage: adversarial Epoch[0] D Loss: 0.000888 G Loss: 7.746345 D(Real): 0.999552 D(Fake1)/D(Fake2): 0.000440/0.000432.\n","Train stage: adversarial Epoch[0] D Loss: 0.001047 G Loss: 8.463266 D(Real): 0.999166 D(Fake1)/D(Fake2): 0.000212/0.000211.\n","Train stage: adversarial Epoch[0] D Loss: 0.001336 G Loss: 6.901847 D(Real): 0.999713 D(Fake1)/D(Fake2): 0.001049/0.001006.\n","Train stage: adversarial Epoch[0] D Loss: 0.000895 G Loss: 8.290061 D(Real): 0.999358 D(Fake1)/D(Fake2): 0.000252/0.000251.\n","Train stage: adversarial Epoch[0] D Loss: 0.001151 G Loss: 6.984634 D(Real): 0.999814 D(Fake1)/D(Fake2): 0.000965/0.000926.\n","Train stage: adversarial Epoch[0] D Loss: 0.000175 G Loss: 9.427073 D(Real): 0.999905 D(Fake1)/D(Fake2): 0.000081/0.000081.\n","Train stage: adversarial Epoch[0] D Loss: 0.000851 G Loss: 8.022182 D(Real): 0.999483 D(Fake1)/D(Fake2): 0.000333/0.000328.\n","Train stage: adversarial Epoch[0] D Loss: 0.000402 G Loss: 8.602962 D(Real): 0.999783 D(Fake1)/D(Fake2): 0.000184/0.000184.\n","Train stage: adversarial Epoch[0] D Loss: 0.000336 G Loss: 9.099074 D(Real): 0.999776 D(Fake1)/D(Fake2): 0.000112/0.000112.\n","Train stage: adversarial Epoch[0] D Loss: 0.000291 G Loss: 8.522841 D(Real): 0.999909 D(Fake1)/D(Fake2): 0.000200/0.000199.\n","Train stage: adversarial Epoch[0] D Loss: 0.000248 G Loss: 9.550431 D(Real): 0.999823 D(Fake1)/D(Fake2): 0.000071/0.000071.\n","Train stage: adversarial Epoch[0] D Loss: 0.000225 G Loss: 9.317646 D(Real): 0.999865 D(Fake1)/D(Fake2): 0.000090/0.000090.\n","Train stage: adversarial Epoch[0] D Loss: 0.000527 G Loss: 7.712948 D(Real): 0.999934 D(Fake1)/D(Fake2): 0.000461/0.000447.\n","Train stage: adversarial Epoch[0] D Loss: 0.000231 G Loss: 9.331065 D(Real): 0.999858 D(Fake1)/D(Fake2): 0.000089/0.000089.\n","Train stage: adversarial Epoch[0] D Loss: 0.000501 G Loss: 9.246772 D(Real): 0.999595 D(Fake1)/D(Fake2): 0.000096/0.000096.\n","Train stage: adversarial Epoch[0] D Loss: 0.000752 G Loss: 9.689079 D(Real): 0.999311 D(Fake1)/D(Fake2): 0.000062/0.000062.\n","Train stage: adversarial Epoch[0] D Loss: 0.001702 G Loss: 9.841039 D(Real): 0.998352 D(Fake1)/D(Fake2): 0.000053/0.000053.\n","Train stage: adversarial Epoch[0] D Loss: 0.000742 G Loss: 9.824381 D(Real): 0.999313 D(Fake1)/D(Fake2): 0.000054/0.000054.\n","Train stage: adversarial Epoch[0] D Loss: 0.000372 G Loss: 9.434796 D(Real): 0.999708 D(Fake1)/D(Fake2): 0.000080/0.000080.\n","Train stage: adversarial Epoch[0] D Loss: 0.000186 G Loss: 9.088042 D(Real): 0.999928 D(Fake1)/D(Fake2): 0.000114/0.000113.\n","Train stage: adversarial Epoch[0] D Loss: 0.000281 G Loss: 9.522238 D(Real): 0.999793 D(Fake1)/D(Fake2): 0.000073/0.000073.\n","Train stage: adversarial Epoch[0] D Loss: 0.000131 G Loss: 9.395671 D(Real): 0.999952 D(Fake1)/D(Fake2): 0.000084/0.000083.\n","Train stage: adversarial Epoch[0] D Loss: 0.000416 G Loss: 8.937982 D(Real): 0.999716 D(Fake1)/D(Fake2): 0.000132/0.000131.\n","Train stage: adversarial Epoch[0] D Loss: 0.000335 G Loss: 9.802855 D(Real): 0.999720 D(Fake1)/D(Fake2): 0.000055/0.000055.\n","Train stage: adversarial Epoch[0] D Loss: 0.000152 G Loss: 9.133763 D(Real): 0.999956 D(Fake1)/D(Fake2): 0.000109/0.000108.\n","Train stage: adversarial Epoch[0] D Loss: 0.000529 G Loss: 8.037333 D(Real): 0.999800 D(Fake1)/D(Fake2): 0.000329/0.000323.\n","Train stage: adversarial Epoch[0] D Loss: 0.001196 G Loss: 6.899938 D(Real): 0.999874 D(Fake1)/D(Fake2): 0.001070/0.001008.\n","Train stage: adversarial Epoch[0] D Loss: 0.002080 G Loss: 9.141006 D(Real): 0.998029 D(Fake1)/D(Fake2): 0.000107/0.000107.\n","Train stage: adversarial Epoch[0] D Loss: 0.000605 G Loss: 7.700177 D(Real): 0.999862 D(Fake1)/D(Fake2): 0.000467/0.000453.\n","Train stage: adversarial Epoch[0] D Loss: 0.000324 G Loss: 9.323732 D(Real): 0.999766 D(Fake1)/D(Fake2): 0.000090/0.000089.\n","Train stage: adversarial Epoch[0] D Loss: 0.000474 G Loss: 7.861290 D(Real): 0.999920 D(Fake1)/D(Fake2): 0.000394/0.000385.\n","Train stage: adversarial Epoch[0] D Loss: 0.000244 G Loss: 9.106689 D(Real): 0.999868 D(Fake1)/D(Fake2): 0.000111/0.000111.\n","Train stage: adversarial Epoch[0] D Loss: 0.000944 G Loss: 7.117671 D(Real): 0.999903 D(Fake1)/D(Fake2): 0.000846/0.000811.\n","Train stage: adversarial Epoch[0] D Loss: 0.000133 G Loss: 9.245015 D(Real): 0.999964 D(Fake1)/D(Fake2): 0.000097/0.000097.\n","Train stage: adversarial Epoch[0] D Loss: 0.000661 G Loss: 8.901682 D(Real): 0.999476 D(Fake1)/D(Fake2): 0.000137/0.000136.\n","Train stage: adversarial Epoch[0] D Loss: 0.000747 G Loss: 10.204659 D(Real): 0.999290 D(Fake1)/D(Fake2): 0.000037/0.000037.\n","Train stage: adversarial Epoch[0] D Loss: 0.000277 G Loss: 9.947962 D(Real): 0.999771 D(Fake1)/D(Fake2): 0.000048/0.000048.\n","Train stage: adversarial Epoch[0] D Loss: 0.000208 G Loss: 8.963832 D(Real): 0.999921 D(Fake1)/D(Fake2): 0.000129/0.000128.\n","Train stage: adversarial Epoch[0] D Loss: 0.000546 G Loss: 9.964602 D(Real): 0.999501 D(Fake1)/D(Fake2): 0.000047/0.000047.\n","Train stage: adversarial Epoch[0] D Loss: 0.000995 G Loss: 7.038154 D(Real): 0.999931 D(Fake1)/D(Fake2): 0.000926/0.000878.\n","Train stage: adversarial Epoch[0] D Loss: 0.000193 G Loss: 9.737522 D(Real): 0.999866 D(Fake1)/D(Fake2): 0.000059/0.000059.\n","Train stage: adversarial Epoch[0] D Loss: 0.000452 G Loss: 8.376034 D(Real): 0.999781 D(Fake1)/D(Fake2): 0.000233/0.000230.\n","Train stage: adversarial Epoch[0] D Loss: 0.000127 G Loss: 9.343200 D(Real): 0.999960 D(Fake1)/D(Fake2): 0.000087/0.000088.\n","Train stage: adversarial Epoch[0] D Loss: 0.000170 G Loss: 9.450326 D(Real): 0.999909 D(Fake1)/D(Fake2): 0.000079/0.000079.\n","Train stage: adversarial Epoch[0] D Loss: 0.000120 G Loss: 10.321560 D(Real): 0.999913 D(Fake1)/D(Fake2): 0.000033/0.000033.\n","Train stage: adversarial Epoch[0] D Loss: 0.000222 G Loss: 10.058120 D(Real): 0.999821 D(Fake1)/D(Fake2): 0.000043/0.000043.\n","Train stage: adversarial Epoch[0] D Loss: 0.001590 G Loss: 9.894582 D(Real): 0.998462 D(Fake1)/D(Fake2): 0.000050/0.000050.\n","Train stage: adversarial Epoch[0] D Loss: 0.000530 G Loss: 7.929037 D(Real): 0.999839 D(Fake1)/D(Fake2): 0.000369/0.000360.\n","Train stage: adversarial Epoch[0] D Loss: 0.000169 G Loss: 8.829527 D(Real): 0.999979 D(Fake1)/D(Fake2): 0.000148/0.000146.\n","Train stage: adversarial Epoch[0] D Loss: 0.000069 G Loss: 9.954813 D(Real): 0.999979 D(Fake1)/D(Fake2): 0.000048/0.000047.\n","Train stage: adversarial Epoch[0] D Loss: 0.000818 G Loss: 10.078587 D(Real): 0.999224 D(Fake1)/D(Fake2): 0.000042/0.000042.\n","Train stage: adversarial Epoch[0] D Loss: 0.000313 G Loss: 8.764791 D(Real): 0.999846 D(Fake1)/D(Fake2): 0.000159/0.000156.\n","Train stage: adversarial Epoch[0] D Loss: 0.000143 G Loss: 10.093320 D(Real): 0.999899 D(Fake1)/D(Fake2): 0.000041/0.000041.\n","Train stage: adversarial Epoch[0] D Loss: 0.000361 G Loss: 9.654757 D(Real): 0.999704 D(Fake1)/D(Fake2): 0.000064/0.000064.\n","Train stage: adversarial Epoch[0] D Loss: 0.000725 G Loss: 10.499837 D(Real): 0.999303 D(Fake1)/D(Fake2): 0.000028/0.000028.\n","Train stage: adversarial Epoch[0] D Loss: 0.000327 G Loss: 10.237811 D(Real): 0.999709 D(Fake1)/D(Fake2): 0.000036/0.000036.\n","Train stage: adversarial Epoch[0] D Loss: 0.000510 G Loss: 10.015464 D(Real): 0.999535 D(Fake1)/D(Fake2): 0.000045/0.000045.\n","Train stage: adversarial Epoch[0] D Loss: 0.000236 G Loss: 8.602842 D(Real): 0.999950 D(Fake1)/D(Fake2): 0.000186/0.000184.\n","Train stage: adversarial Epoch[0] D Loss: 0.000092 G Loss: 9.649211 D(Real): 0.999974 D(Fake1)/D(Fake2): 0.000066/0.000064.\n","Train stage: adversarial Epoch[0] D Loss: 0.000501 G Loss: 7.670426 D(Real): 0.999981 D(Fake1)/D(Fake2): 0.000482/0.000466.\n","Train stage: adversarial Epoch[0] D Loss: 0.000113 G Loss: 10.705290 D(Real): 0.999910 D(Fake1)/D(Fake2): 0.000022/0.000022.\n","Train stage: adversarial Epoch[0] D Loss: 0.000085 G Loss: 9.848475 D(Real): 0.999968 D(Fake1)/D(Fake2): 0.000053/0.000053.\n","Train stage: adversarial Epoch[0] D Loss: 0.000223 G Loss: 10.165982 D(Real): 0.999816 D(Fake1)/D(Fake2): 0.000039/0.000038.\n","Train stage: adversarial Epoch[1] D Loss: 0.000177 G Loss: 10.632229 D(Real): 0.999847 D(Fake1)/D(Fake2): 0.000024/0.000024.\n","Train stage: adversarial Epoch[1] D Loss: 0.000685 G Loss: 12.253299 D(Real): 0.999320 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000026 G Loss: 11.868917 D(Real): 0.999981 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000194 G Loss: 11.098844 D(Real): 0.999821 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[1] D Loss: 0.000065 G Loss: 11.316527 D(Real): 0.999948 D(Fake1)/D(Fake2): 0.000012/0.000012.\n","Train stage: adversarial Epoch[1] D Loss: 0.000320 G Loss: 11.745924 D(Real): 0.999688 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[1] D Loss: 0.000142 G Loss: 11.904211 D(Real): 0.999865 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000267 G Loss: 12.010057 D(Real): 0.999739 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000451 G Loss: 10.189016 D(Real): 0.999586 D(Fake1)/D(Fake2): 0.000038/0.000038.\n","Train stage: adversarial Epoch[1] D Loss: 0.001488 G Loss: 12.124373 D(Real): 0.998519 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000462 G Loss: 11.320008 D(Real): 0.999550 D(Fake1)/D(Fake2): 0.000012/0.000012.\n","Train stage: adversarial Epoch[1] D Loss: 0.000067 G Loss: 12.043517 D(Real): 0.999938 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000741 G Loss: 11.880770 D(Real): 0.999267 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000039 G Loss: 11.190660 D(Real): 0.999975 D(Fake1)/D(Fake2): 0.000014/0.000014.\n","Train stage: adversarial Epoch[1] D Loss: 0.000045 G Loss: 10.708117 D(Real): 0.999977 D(Fake1)/D(Fake2): 0.000022/0.000022.\n","Train stage: adversarial Epoch[1] D Loss: 0.000119 G Loss: 11.687314 D(Real): 0.999889 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[1] D Loss: 0.000041 G Loss: 11.842984 D(Real): 0.999966 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000023 G Loss: 10.915541 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000018/0.000018.\n","Train stage: adversarial Epoch[1] D Loss: 0.000074 G Loss: 9.660933 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000064/0.000064.\n","Train stage: adversarial Epoch[1] D Loss: 0.000126 G Loss: 10.822588 D(Real): 0.999894 D(Fake1)/D(Fake2): 0.000020/0.000020.\n","Train stage: adversarial Epoch[1] D Loss: 0.000024 G Loss: 11.958607 D(Real): 0.999982 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000033 G Loss: 11.083381 D(Real): 0.999982 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[1] D Loss: 0.000086 G Loss: 12.331718 D(Real): 0.999918 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000059 G Loss: 11.237189 D(Real): 0.999954 D(Fake1)/D(Fake2): 0.000013/0.000013.\n","Train stage: adversarial Epoch[1] D Loss: 0.000213 G Loss: 11.634679 D(Real): 0.999796 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[1] D Loss: 0.000307 G Loss: 11.900073 D(Real): 0.999700 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000047 G Loss: 11.877268 D(Real): 0.999960 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000131 G Loss: 10.482721 D(Real): 0.999897 D(Fake1)/D(Fake2): 0.000028/0.000028.\n","Train stage: adversarial Epoch[1] D Loss: 0.000247 G Loss: 11.659073 D(Real): 0.999762 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[1] D Loss: 0.000020 G Loss: 12.276518 D(Real): 0.999984 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000031 G Loss: 11.137562 D(Real): 0.999984 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[1] D Loss: 0.001636 G Loss: 12.148719 D(Real): 0.998370 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000043 G Loss: 10.602274 D(Real): 0.999982 D(Fake1)/D(Fake2): 0.000025/0.000025.\n","Train stage: adversarial Epoch[1] D Loss: 0.000025 G Loss: 11.450319 D(Real): 0.999986 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[1] D Loss: 0.000035 G Loss: 12.142556 D(Real): 0.999970 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000072 G Loss: 10.564596 D(Real): 0.999954 D(Fake1)/D(Fake2): 0.000026/0.000026.\n","Train stage: adversarial Epoch[1] D Loss: 0.000376 G Loss: 12.036251 D(Real): 0.999630 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000066 G Loss: 10.850891 D(Real): 0.999953 D(Fake1)/D(Fake2): 0.000019/0.000019.\n","Train stage: adversarial Epoch[1] D Loss: 0.000073 G Loss: 11.513049 D(Real): 0.999937 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[1] D Loss: 0.000195 G Loss: 12.202325 D(Real): 0.999810 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000392 G Loss: 12.103729 D(Real): 0.999614 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000087 G Loss: 10.263987 D(Real): 0.999948 D(Fake1)/D(Fake2): 0.000035/0.000035.\n","Train stage: adversarial Epoch[1] D Loss: 0.000087 G Loss: 11.929795 D(Real): 0.999920 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000041 G Loss: 10.642296 D(Real): 0.999983 D(Fake1)/D(Fake2): 0.000024/0.000024.\n","Train stage: adversarial Epoch[1] D Loss: 0.000054 G Loss: 11.628051 D(Real): 0.999955 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[1] D Loss: 0.000057 G Loss: 10.058552 D(Real): 0.999986 D(Fake1)/D(Fake2): 0.000043/0.000043.\n","Train stage: adversarial Epoch[1] D Loss: 0.000263 G Loss: 11.686980 D(Real): 0.999745 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[1] D Loss: 0.000125 G Loss: 11.906057 D(Real): 0.999882 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000033 G Loss: 10.514336 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000027/0.000027.\n","Train stage: adversarial Epoch[1] D Loss: 0.000034 G Loss: 10.976596 D(Real): 0.999983 D(Fake1)/D(Fake2): 0.000017/0.000017.\n","Train stage: adversarial Epoch[1] D Loss: 0.000022 G Loss: 11.909122 D(Real): 0.999984 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000045 G Loss: 10.985872 D(Real): 0.999972 D(Fake1)/D(Fake2): 0.000017/0.000017.\n","Train stage: adversarial Epoch[1] D Loss: 0.000159 G Loss: 11.155678 D(Real): 0.999855 D(Fake1)/D(Fake2): 0.000014/0.000014.\n","Train stage: adversarial Epoch[1] D Loss: 0.000046 G Loss: 11.075232 D(Real): 0.999969 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[1] D Loss: 0.000035 G Loss: 10.494609 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000028/0.000028.\n","Train stage: adversarial Epoch[1] D Loss: 0.000027 G Loss: 11.836136 D(Real): 0.999980 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[1] D Loss: 0.000083 G Loss: 10.833130 D(Real): 0.999937 D(Fake1)/D(Fake2): 0.000020/0.000020.\n","Train stage: adversarial Epoch[1] D Loss: 0.000035 G Loss: 12.045312 D(Real): 0.999971 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000029 G Loss: 11.199244 D(Real): 0.999985 D(Fake1)/D(Fake2): 0.000014/0.000014.\n","Train stage: adversarial Epoch[1] D Loss: 0.000053 G Loss: 11.283673 D(Real): 0.999959 D(Fake1)/D(Fake2): 0.000013/0.000013.\n","Train stage: adversarial Epoch[1] D Loss: 0.000054 G Loss: 11.603849 D(Real): 0.999955 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[1] D Loss: 0.000070 G Loss: 11.969639 D(Real): 0.999936 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000015 G Loss: 12.240514 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000051 G Loss: 10.683862 D(Real): 0.999972 D(Fake1)/D(Fake2): 0.000023/0.000023.\n","Train stage: adversarial Epoch[1] D Loss: 0.000009 G Loss: 12.034006 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000066 G Loss: 12.121019 D(Real): 0.999939 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000065 G Loss: 10.454391 D(Real): 0.999964 D(Fake1)/D(Fake2): 0.000029/0.000029.\n","Train stage: adversarial Epoch[1] D Loss: 0.000028 G Loss: 11.117373 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[1] D Loss: 0.000197 G Loss: 12.011168 D(Real): 0.999809 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000060 G Loss: 10.306195 D(Real): 0.999974 D(Fake1)/D(Fake2): 0.000034/0.000033.\n","Train stage: adversarial Epoch[1] D Loss: 0.000041 G Loss: 10.289097 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000034/0.000034.\n","Train stage: adversarial Epoch[1] D Loss: 0.000035 G Loss: 10.515734 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000027/0.000027.\n","Train stage: adversarial Epoch[1] D Loss: 0.000105 G Loss: 11.974693 D(Real): 0.999901 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000241 G Loss: 8.375231 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000237/0.000231.\n","Train stage: adversarial Epoch[1] D Loss: 0.000266 G Loss: 10.562963 D(Real): 0.999760 D(Fake1)/D(Fake2): 0.000026/0.000026.\n","Train stage: adversarial Epoch[1] D Loss: 0.000127 G Loss: 12.252974 D(Real): 0.999878 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[1] D Loss: 0.000031 G Loss: 11.610462 D(Real): 0.999978 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[1] D Loss: 0.000045 G Loss: 12.436723 D(Real): 0.999959 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000011 G Loss: 12.377245 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000052 G Loss: 12.481365 D(Real): 0.999951 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000095 G Loss: 12.514703 D(Real): 0.999908 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000049 G Loss: 10.174150 D(Real): 0.999989 D(Fake1)/D(Fake2): 0.000038/0.000038.\n","Train stage: adversarial Epoch[1] D Loss: 0.000044 G Loss: 12.551358 D(Real): 0.999960 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000087 G Loss: 9.495406 D(Real): 0.999989 D(Fake1)/D(Fake2): 0.000076/0.000075.\n","Train stage: adversarial Epoch[1] D Loss: 0.000024 G Loss: 10.782650 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000021/0.000021.\n","Train stage: adversarial Epoch[1] D Loss: 0.000012 G Loss: 12.034012 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000018 G Loss: 12.089044 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[1] D Loss: 0.000314 G Loss: 12.617992 D(Real): 0.999689 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[1] D Loss: 0.000045 G Loss: 10.613206 D(Real): 0.999980 D(Fake1)/D(Fake2): 0.000025/0.000025.\n","Train stage: adversarial Epoch[1] D Loss: 0.000407 G Loss: 12.480878 D(Real): 0.999597 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000039 G Loss: 12.400536 D(Real): 0.999965 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000059 G Loss: 10.285105 D(Real): 0.999975 D(Fake1)/D(Fake2): 0.000034/0.000034.\n","Train stage: adversarial Epoch[1] D Loss: 0.000012 G Loss: 12.335639 D(Real): 0.999992 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000023 G Loss: 10.971853 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000017/0.000017.\n","Train stage: adversarial Epoch[1] D Loss: 0.000267 G Loss: 12.655150 D(Real): 0.999736 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[1] D Loss: 0.000033 G Loss: 11.683736 D(Real): 0.999976 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[1] D Loss: 0.000044 G Loss: 12.535950 D(Real): 0.999960 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000023 G Loss: 12.515866 D(Real): 0.999981 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000075 G Loss: 12.548676 D(Real): 0.999928 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[1] D Loss: 0.000021 G Loss: 11.082712 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[1] D Loss: 0.000025 G Loss: 11.331092 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000012/0.000012.\n","Train stage: adversarial Epoch[2] D Loss: 0.000360 G Loss: 10.301766 D(Real): 0.999673 D(Fake1)/D(Fake2): 0.000033/0.000034.\n","Train stage: adversarial Epoch[2] D Loss: 0.000023 G Loss: 11.128344 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[2] D Loss: 0.000037 G Loss: 10.581371 D(Real): 0.999988 D(Fake1)/D(Fake2): 0.000025/0.000025.\n","Train stage: adversarial Epoch[2] D Loss: 0.000122 G Loss: 12.381891 D(Real): 0.999882 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000092 G Loss: 12.527240 D(Real): 0.999912 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000089 G Loss: 12.204376 D(Real): 0.999916 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000014 G Loss: 11.578263 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[2] D Loss: 0.000201 G Loss: 9.899646 D(Real): 0.999850 D(Fake1)/D(Fake2): 0.000050/0.000050.\n","Train stage: adversarial Epoch[2] D Loss: 0.000058 G Loss: 12.906713 D(Real): 0.999945 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[2] D Loss: 0.000026 G Loss: 12.110709 D(Real): 0.999980 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[2] D Loss: 0.000124 G Loss: 9.024887 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000122/0.000120.\n","Train stage: adversarial Epoch[2] D Loss: 0.000071 G Loss: 9.705709 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000062/0.000061.\n","Train stage: adversarial Epoch[2] D Loss: 0.000010 G Loss: 12.102088 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[2] D Loss: 0.000037 G Loss: 11.857200 D(Real): 0.999970 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[2] D Loss: 0.000038 G Loss: 11.981571 D(Real): 0.999969 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[2] D Loss: 0.000116 G Loss: 12.134486 D(Real): 0.999890 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000053 G Loss: 12.458379 D(Real): 0.999951 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000008 G Loss: 12.295029 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000040 G Loss: 12.845007 D(Real): 0.999962 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000013 G Loss: 11.853149 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[2] D Loss: 0.000098 G Loss: 9.267210 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000096/0.000094.\n","Train stage: adversarial Epoch[2] D Loss: 0.000050 G Loss: 12.190564 D(Real): 0.999956 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000013 G Loss: 12.129191 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000006/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000037 G Loss: 12.418020 D(Real): 0.999967 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000030 G Loss: 12.249347 D(Real): 0.999975 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000016 G Loss: 11.295666 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000012/0.000012.\n","Train stage: adversarial Epoch[2] D Loss: 0.000035 G Loss: 11.486785 D(Real): 0.999975 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[2] D Loss: 0.000010 G Loss: 12.590531 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000017 G Loss: 12.724235 D(Real): 0.999986 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000267 G Loss: 12.805511 D(Real): 0.999736 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000015 G Loss: 11.424252 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[2] D Loss: 0.000111 G Loss: 12.835943 D(Real): 0.999892 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 11.445058 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[2] D Loss: 0.000009 G Loss: 12.866672 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000086 G Loss: 9.461631 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000079/0.000078.\n","Train stage: adversarial Epoch[2] D Loss: 0.000011 G Loss: 12.178845 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000511 G Loss: 12.155451 D(Real): 0.999494 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000012 G Loss: 11.726460 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[2] D Loss: 0.000012 G Loss: 12.062436 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[2] D Loss: 0.000187 G Loss: 12.655044 D(Real): 0.999816 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000236 G Loss: 12.293338 D(Real): 0.999769 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000009 G Loss: 11.865186 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[2] D Loss: 0.000063 G Loss: 9.841024 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000054/0.000053.\n","Train stage: adversarial Epoch[2] D Loss: 0.000067 G Loss: 9.673654 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000063/0.000063.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 11.598351 D(Real): 0.999989 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[2] D Loss: 0.000015 G Loss: 11.492601 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[2] D Loss: 0.000010 G Loss: 12.618010 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000017 G Loss: 11.942529 D(Real): 0.999989 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[2] D Loss: 0.000067 G Loss: 11.921887 D(Real): 0.999939 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[2] D Loss: 0.000029 G Loss: 11.024599 D(Real): 0.999988 D(Fake1)/D(Fake2): 0.000016/0.000016.\n","Train stage: adversarial Epoch[2] D Loss: 0.000033 G Loss: 12.426348 D(Real): 0.999971 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000010 G Loss: 11.989763 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[2] D Loss: 0.000041 G Loss: 10.155287 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000039/0.000039.\n","Train stage: adversarial Epoch[2] D Loss: 0.000215 G Loss: 12.843392 D(Real): 0.999788 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 11.820008 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[2] D Loss: 0.000049 G Loss: 12.717056 D(Real): 0.999954 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000010 G Loss: 11.621883 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[2] D Loss: 0.000024 G Loss: 10.768661 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000021/0.000021.\n","Train stage: adversarial Epoch[2] D Loss: 0.000015 G Loss: 11.679345 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 12.205476 D(Real): 0.999985 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000125 G Loss: 9.027103 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000123/0.000120.\n","Train stage: adversarial Epoch[2] D Loss: 0.000019 G Loss: 12.751432 D(Real): 0.999984 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000008 G Loss: 12.543486 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000018 G Loss: 12.511774 D(Real): 0.999986 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000019 G Loss: 11.388520 D(Real): 0.999992 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[2] D Loss: 0.000012 G Loss: 11.552078 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[2] D Loss: 0.000067 G Loss: 9.634132 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000066/0.000065.\n","Train stage: adversarial Epoch[2] D Loss: 0.000009 G Loss: 12.606665 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000025 G Loss: 12.518084 D(Real): 0.999979 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 11.361455 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000012/0.000012.\n","Train stage: adversarial Epoch[2] D Loss: 0.000009 G Loss: 12.126732 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000030 G Loss: 12.913270 D(Real): 0.999973 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[2] D Loss: 0.000011 G Loss: 11.677592 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000009/0.000008.\n","Train stage: adversarial Epoch[2] D Loss: 0.000002 G Loss: 13.342441 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[2] D Loss: 0.000014 G Loss: 12.185308 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000030 G Loss: 12.652644 D(Real): 0.999973 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000009 G Loss: 12.032404 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[2] D Loss: 0.000026 G Loss: 10.718935 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000022/0.000022.\n","Train stage: adversarial Epoch[2] D Loss: 0.000010 G Loss: 11.573921 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[2] D Loss: 0.000030 G Loss: 12.874080 D(Real): 0.999973 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000040 G Loss: 12.303857 D(Real): 0.999965 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000143 G Loss: 8.913116 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000138/0.000135.\n","Train stage: adversarial Epoch[2] D Loss: 0.000008 G Loss: 12.461654 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[2] D Loss: 0.000014 G Loss: 11.686621 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[2] D Loss: 0.000033 G Loss: 11.453995 D(Real): 0.999978 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[2] D Loss: 0.000017 G Loss: 12.114646 D(Real): 0.999989 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[2] D Loss: 0.000025 G Loss: 11.772562 D(Real): 0.999982 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[2] D Loss: 0.000025 G Loss: 12.755271 D(Real): 0.999978 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 11.083174 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[2] D Loss: 0.000276 G Loss: 8.253927 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000276/0.000260.\n","Train stage: adversarial Epoch[2] D Loss: 0.000033 G Loss: 12.782558 D(Real): 0.999970 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 12.786302 D(Real): 0.999983 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[2] D Loss: 0.000020 G Loss: 11.040971 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000016/0.000016.\n","Train stage: adversarial Epoch[2] D Loss: 0.000010 G Loss: 11.810541 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[2] D Loss: 0.000021 G Loss: 11.115129 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[2] D Loss: 0.000015 G Loss: 11.661734 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[2] D Loss: 0.000029 G Loss: 10.589687 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000025/0.000025.\n","Train stage: adversarial Epoch[2] D Loss: 0.000064 G Loss: 9.718221 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000061/0.000060.\n","Train stage: adversarial Epoch[2] D Loss: 0.000013 G Loss: 11.766040 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[2] D Loss: 0.000011 G Loss: 11.964499 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[2] D Loss: 0.000006 G Loss: 12.271063 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[3] D Loss: 0.000029 G Loss: 11.790488 D(Real): 0.999979 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[3] D Loss: 0.000018 G Loss: 11.390338 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[3] D Loss: 0.000013 G Loss: 12.140534 D(Real): 0.999992 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[3] D Loss: 0.000011 G Loss: 11.522150 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[3] D Loss: 0.000027 G Loss: 12.343497 D(Real): 0.999977 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000274 G Loss: 8.288066 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000273/0.000252.\n","Train stage: adversarial Epoch[3] D Loss: 0.000049 G Loss: 10.065739 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000043/0.000043.\n","Train stage: adversarial Epoch[3] D Loss: 0.000016 G Loss: 12.003916 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[3] D Loss: 0.000029 G Loss: 10.674342 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000023/0.000023.\n","Train stage: adversarial Epoch[3] D Loss: 0.000027 G Loss: 12.114554 D(Real): 0.999979 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[3] D Loss: 0.000109 G Loss: 12.871027 D(Real): 0.999894 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000008 G Loss: 12.534896 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000021 G Loss: 10.978903 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000017/0.000017.\n","Train stage: adversarial Epoch[3] D Loss: 0.000012 G Loss: 12.399468 D(Real): 0.999992 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000020 G Loss: 11.992333 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[3] D Loss: 0.000009 G Loss: 11.836234 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[3] D Loss: 0.000001 G Loss: 14.019332 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000011 G Loss: 13.051104 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000008 G Loss: 11.785639 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[3] D Loss: 0.000018 G Loss: 11.375847 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[3] D Loss: 0.000039 G Loss: 10.180243 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000038/0.000038.\n","Train stage: adversarial Epoch[3] D Loss: 0.000008 G Loss: 11.747613 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[3] D Loss: 0.000037 G Loss: 12.806930 D(Real): 0.999965 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000012 G Loss: 12.364939 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000023 G Loss: 11.757400 D(Real): 0.999985 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[3] D Loss: 0.000011 G Loss: 13.175055 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000008 G Loss: 12.467829 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000010 G Loss: 11.850810 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[3] D Loss: 0.000017 G Loss: 12.867436 D(Real): 0.999986 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000012 G Loss: 11.440351 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[3] D Loss: 0.000017 G Loss: 11.840670 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[3] D Loss: 0.000313 G Loss: 8.174246 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000308/0.000282.\n","Train stage: adversarial Epoch[3] D Loss: 0.000014 G Loss: 11.560653 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[3] D Loss: 0.000019 G Loss: 11.154233 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000014/0.000014.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 12.247981 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 12.960860 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000053 G Loss: 13.139373 D(Real): 0.999949 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 12.903008 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000023 G Loss: 10.806454 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000020/0.000020.\n","Train stage: adversarial Epoch[3] D Loss: 0.000015 G Loss: 11.398888 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000011/0.000011.\n","Train stage: adversarial Epoch[3] D Loss: 0.000005 G Loss: 12.775629 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 12.711827 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000009 G Loss: 12.821506 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000029 G Loss: 10.486867 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000028/0.000028.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 13.318015 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 13.444387 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000055 G Loss: 12.798202 D(Real): 0.999948 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000005 G Loss: 12.546707 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000010 G Loss: 11.952310 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[3] D Loss: 0.000028 G Loss: 13.505037 D(Real): 0.999973 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000026 G Loss: 11.464337 D(Real): 0.999985 D(Fake1)/D(Fake2): 0.000011/0.000010.\n","Train stage: adversarial Epoch[3] D Loss: 0.000026 G Loss: 12.797343 D(Real): 0.999977 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000031 G Loss: 12.781987 D(Real): 0.999971 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000034 G Loss: 10.354084 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000032/0.000032.\n","Train stage: adversarial Epoch[3] D Loss: 0.000012 G Loss: 13.044306 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000020 G Loss: 13.812276 D(Real): 0.999981 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000009 G Loss: 13.035542 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000007 G Loss: 12.235209 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[3] D Loss: 0.000007 G Loss: 12.037907 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[3] D Loss: 0.000688 G Loss: 7.547874 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000687/0.000527.\n","Train stage: adversarial Epoch[3] D Loss: 0.000038 G Loss: 10.214726 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000037/0.000037.\n","Train stage: adversarial Epoch[3] D Loss: 0.000015 G Loss: 13.210503 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000007 G Loss: 13.268418 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000080 G Loss: 13.059443 D(Real): 0.999922 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000024 G Loss: 10.692392 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000023/0.000023.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 12.465344 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000003 G Loss: 13.647822 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 13.144732 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000008 G Loss: 13.265160 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 12.399589 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000018 G Loss: 13.579391 D(Real): 0.999984 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000009 G Loss: 12.005422 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[3] D Loss: 0.000013 G Loss: 11.297121 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000012/0.000012.\n","Train stage: adversarial Epoch[3] D Loss: 0.000011 G Loss: 11.498656 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[3] D Loss: 0.000005 G Loss: 13.621226 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000018 G Loss: 11.080017 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000015/0.000015.\n","Train stage: adversarial Epoch[3] D Loss: 0.000009 G Loss: 13.267229 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000020 G Loss: 13.633948 D(Real): 0.999981 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 12.834399 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 13.793435 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 13.259828 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000015 G Loss: 12.346606 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 13.177433 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000012 G Loss: 12.879639 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000009 G Loss: 13.891795 D(Real): 0.999992 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000005 G Loss: 12.776469 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000003 G Loss: 13.320332 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000010 G Loss: 11.772066 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[3] D Loss: 0.000003 G Loss: 13.253387 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000013 G Loss: 13.201230 D(Real): 0.999989 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000003 G Loss: 13.236388 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000003 G Loss: 13.719152 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000057 G Loss: 11.566146 D(Real): 0.999952 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[3] D Loss: 0.000068 G Loss: 13.271390 D(Real): 0.999933 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[3] D Loss: 0.000096 G Loss: 14.141324 D(Real): 0.999905 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 12.275683 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[3] D Loss: 0.000007 G Loss: 12.879106 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[3] D Loss: 0.000002 G Loss: 14.138361 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000006 G Loss: 12.139493 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[3] D Loss: 0.000003 G Loss: 13.827643 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[3] D Loss: 0.000004 G Loss: 13.083520 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000007 G Loss: 11.985801 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 12.647707 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 13.768708 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000017 G Loss: 13.645716 D(Real): 0.999985 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 13.938848 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000007 G Loss: 13.794851 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000048 G Loss: 9.984248 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000047/0.000046.\n","Train stage: adversarial Epoch[4] D Loss: 0.000010 G Loss: 11.981651 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000006/0.000006.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 13.852878 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 13.369138 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 13.349455 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 12.648050 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 12.413405 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.783472 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 12.172636 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[4] D Loss: 0.000018 G Loss: 11.359162 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000012/0.000012.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.531301 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000007 G Loss: 12.324139 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 12.973308 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.937817 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000011 G Loss: 12.321349 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 13.523508 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 14.126987 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 14.166114 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 13.206831 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000031 G Loss: 14.010428 D(Real): 0.999969 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000084 G Loss: 9.425243 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000084/0.000081.\n","Train stage: adversarial Epoch[4] D Loss: 0.000010 G Loss: 13.748158 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.309542 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.814129 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000029 G Loss: 13.392696 D(Real): 0.999972 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 13.138369 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000039 G Loss: 14.520999 D(Real): 0.999961 D(Fake1)/D(Fake2): 0.000000/0.000000.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 13.291327 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.744499 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000001 G Loss: 13.749414 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.883117 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 14.345182 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 12.843446 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[4] D Loss: 0.000008 G Loss: 11.917611 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 14.049372 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 12.271132 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000005/0.000005.\n","Train stage: adversarial Epoch[4] D Loss: 0.000009 G Loss: 11.737965 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[4] D Loss: 0.000009 G Loss: 13.722042 D(Real): 0.999992 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 13.048461 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000011 G Loss: 13.765763 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000001 G Loss: 13.844758 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 14.063169 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.917701 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000010 G Loss: 11.606933 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000009/0.000009.\n","Train stage: adversarial Epoch[4] D Loss: 0.000008 G Loss: 13.031196 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.378288 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 12.111320 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000006/0.000005.\n","Train stage: adversarial Epoch[4] D Loss: 0.000008 G Loss: 13.725715 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.302597 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.737486 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000011 G Loss: 14.238388 D(Real): 0.999990 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.666547 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000009 G Loss: 13.979520 D(Real): 0.999992 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000038 G Loss: 14.507603 D(Real): 0.999962 D(Fake1)/D(Fake2): 0.000000/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000048 G Loss: 14.024161 D(Real): 0.999953 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 12.738214 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 14.011061 D(Real): 0.999996 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 12.540015 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 13.435885 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000014 G Loss: 14.103513 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000017 G Loss: 11.040482 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000016/0.000016.\n","Train stage: adversarial Epoch[4] D Loss: 0.000008 G Loss: 13.738584 D(Real): 0.999993 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000011 G Loss: 11.492891 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000010/0.000010.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.914802 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000008 G Loss: 11.836439 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000007/0.000007.\n","Train stage: adversarial Epoch[4] D Loss: 0.000009 G Loss: 14.606848 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000000/0.000000.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 12.781600 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 14.204432 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 13.944064 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000009 G Loss: 11.728289 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000008/0.000008.\n","Train stage: adversarial Epoch[4] D Loss: 0.000001 G Loss: 13.853982 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000001 G Loss: 14.215871 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000028 G Loss: 14.169589 D(Real): 0.999972 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.493427 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000024 G Loss: 14.521693 D(Real): 0.999977 D(Fake1)/D(Fake2): 0.000000/0.000000.\n","Train stage: adversarial Epoch[4] D Loss: 0.000048 G Loss: 14.380457 D(Real): 0.999953 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 12.983022 D(Real): 0.999997 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000007 G Loss: 14.485922 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000001 G Loss: 14.802967 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000000/0.000000.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 14.151679 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000014 G Loss: 14.036473 D(Real): 0.999987 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 13.845308 D(Real): 0.999995 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000027 G Loss: 11.232565 D(Real): 0.999986 D(Fake1)/D(Fake2): 0.000013/0.000013.\n","Train stage: adversarial Epoch[4] D Loss: 0.000010 G Loss: 13.901279 D(Real): 0.999991 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 14.433795 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 14.265658 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000006 G Loss: 14.429252 D(Real): 0.999994 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 14.339405 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000004 G Loss: 12.593116 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000003/0.000003.\n","Train stage: adversarial Epoch[4] D Loss: 0.000003 G Loss: 12.972283 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000002/0.000002.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.601508 D(Real): 0.999999 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 13.535257 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000001/0.000001.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 12.368228 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000004/0.000004.\n","Train stage: adversarial Epoch[4] D Loss: 0.000005 G Loss: 12.312757 D(Real): 1.000000 D(Fake1)/D(Fake2): 0.000005/0.000004.\n","Train stage: adversarial Epoch[4] D Loss: 0.000002 G Loss: 14.161607 D(Real): 0.999998 D(Fake1)/D(Fake2): 0.000001/0.000001.\n"]}],"source":["for epoch in range(5):\n","    # Train each epoch to generate a model.\n","    train(train_dataloader, epoch)\n","\n","# Save the weight of the model under the last Epoch in this stage.\n","# torch.save(discriminator.state_dict(), os.path.join(exp_dir2, \"d-last.pth\"))\n","# torch.save(generator.state_dict(), os.path.join(exp_dir2, \"g-last.pth\"))"]},{"cell_type":"code","source":["torch.save(generator.to(\"cpu\").state_dict(), \"/content/drive/MyDrive/image_to_str/gen_out.pt\")"],"metadata":{"id":"Gtij1fXxKndd","executionInfo":{"status":"ok","timestamp":1707414254735,"user_tz":-210,"elapsed":945,"user":{"displayName":"Farbod Mohseni","userId":"13682642215773829237"}}},"execution_count":35,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}